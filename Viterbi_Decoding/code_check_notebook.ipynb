{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in training or test data file\n",
    "#\n",
    "def read_data(fname):\n",
    "    exemplars = []\n",
    "    file = open(fname, 'r');\n",
    "    for line in file:\n",
    "        data = tuple([w.lower() for w in line.split()])\n",
    "        exemplars += [ (data[0::2], data[1::2]), ]\n",
    "\n",
    "    return exemplars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData = read_data(\"bc.train\")\n",
    "testData= read_data(\"bc.test\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ytrain = train(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Making Trigram Model\n",
    "\n",
    "AA= {} \n",
    "for tag_seq in Ytrain: \n",
    "    for i in range(len(tag_seq)-2):\n",
    "        if (tag_seq[i],tag_seq[i+1]) not in AA:\n",
    "            AA[(tag_seq[i],tag_seq[i+1])] = {}\n",
    "            AA[(tag_seq[i],tag_seq[i+1])][tag_seq[i+2]] = 1\n",
    "        elif tag_seq[i+2] not in  AA[(tag_seq[i],tag_seq[i+1])]:\n",
    "            AA[(tag_seq[i],tag_seq[i+1])][tag_seq[i+2]] = 1 \n",
    "        else:\n",
    "            AA[(tag_seq[i],tag_seq[i+1])][tag_seq[i+2]] += 1\n",
    "## Changing in probability matrix\n",
    "for states in AA:\n",
    "    sum =0\n",
    "    for state in AA[states]:\n",
    "        sum += AA[states][state]\n",
    "    for state in AA[states]:\n",
    "        AA[states][state]= AA[states][state]*1.0/sum\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.18289033620841402,\n",
       " 1: 0.12902657982749516,\n",
       " 2: 0.05139940151381799,\n",
       " 3: 0.09276535821158247,\n",
       " 4: 0.18676289385671538,\n",
       " 5: 0.08044358387607815,\n",
       " 6: 0.09434958634043303,\n",
       " 7: 0.015138179897905299,\n",
       " 8: 0.06724168280232354,\n",
       " 9: 0.08889280056328111,\n",
       " 10: 0.010737546206653759,\n",
       " 11: 0.0003520506953001232}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AA[(7,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    word2idx,tag2idx = {},{}  #Word Vocabulary with word as key and word_idx as value ,#Tag Vocabulary with Tag as key and Tag_idx as value\n",
    "    word_idx,tag_idx = 0,0  #counter for words , tags\n",
    "    Xtrain,Ytrain = [],[]    #for storing overall Sentence & Tag sequences\n",
    "    currentX,currentY = [],[]  #to store current word sequences (observed Data) & tag sequences (unobserved Data)\n",
    "    for sentence in data:\n",
    "        for word,tag in zip(sentence[0],sentence[1]): \n",
    "            if word not in word2idx:\n",
    "                    word2idx[word] = word_idx\n",
    "                    word_idx += 1\n",
    "            currentX.append(word2idx[word])\n",
    "\n",
    "            if tag not in tag2idx: \n",
    "                tag2idx[tag] = tag_idx\n",
    "                tag_idx += 1\n",
    "            currentY.append(tag2idx[tag])\n",
    "        Xtrain.append(currentX)\n",
    "        Ytrain.append(currentY)\n",
    "        currentX = []\n",
    "        currentY = []\n",
    "\n",
    "    V = len(word2idx) + 1  #Vocabulary Size\n",
    "\n",
    "    # find hidden state, transition matrix and pi\n",
    "    M = max(max(y) for y in Ytrain) + 1 #find total number of hiddent states\n",
    "    A = np.ones((M, M))*(10e-2) # add-one smoothing\n",
    "    pi = np.zeros(M) #initial Matrix\n",
    "    for y in Ytrain:\n",
    "        pi[y[0]] += 1\n",
    "        for i in xrange(len(y)-1):\n",
    "            A[y[i], y[i+1]] += 1\n",
    "\n",
    "    return A,tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A,tag2idx=train(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 114262.2],\n",
       "       [ 235891.2],\n",
       "       [  72697.2],\n",
       "       [ 146148.2],\n",
       "       [ 123936.2],\n",
       "       [  71523.2],\n",
       "       [  44594.2],\n",
       "       [  31503.2],\n",
       "       [  22381.2],\n",
       "       [  33974.2],\n",
       "       [  13495.2],\n",
       "       [   1201.2]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=1,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 5,\n",
       " 'adj': 2,\n",
       " 'adp': 4,\n",
       " 'adv': 6,\n",
       " 'conj': 7,\n",
       " 'det': 0,\n",
       " 'noun': 1,\n",
       " 'num': 10,\n",
       " 'pron': 9,\n",
       " 'prt': 8,\n",
       " 'verb': 3,\n",
       " 'x': 11}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HMM(self, x):\n",
    "    # returns the most likely state sequence given observed sequence x\n",
    "    # using the Viterbi algorithm \n",
    "\n",
    "    x = [self.word2idx[word] for word in x] \n",
    "\n",
    "    T = len(x)\n",
    "    delta = np.zeros((T, self.M))\n",
    "    psi = np.zeros((T, self.M))\n",
    "    delta[0] = np.log(self.pi) + np.log(self.B[:,x[0]]) \n",
    "    for t in xrange(1, T-1):\n",
    "        for j in xrange(self.M): \n",
    "            for k in xrange(self.M)\n",
    "                if t==1:\n",
    "                    delta[t,j] = np.max(delta[t-1] + np.log(self.A[:,j])) + np.log(self.B[j, x[t]])\n",
    "                    psi[t,j] = np.argmax(delta[t-1] + np.log(self.A[:,j]))\n",
    "                else: \n",
    "                    delta[t,j] = np.max(delta[t-1]+ np.log(self.A[j:,k) + np.log(self.B[j, x[t]])\n",
    "                    psi[t,j] = np.argmax(delta[t-1] + np.log(self.A[:,j]))\n",
    "\n",
    "    # backtrack\n",
    "    states = np.zeros(T, dtype=np.int32)\n",
    "    states[T-1] = np.argmax(delta[T-1])\n",
    "    for t in xrange(T-2, -1, -1):\n",
    "        states[t] = psi[t+1, states[t+1]]\n",
    "\n",
    "    tag_states=[]\n",
    "    for i in range(len(states)):\n",
    "        for tag,tag_idx in self.tag2idx.iteritems():\n",
    "            if tag_idx==states[i]: tag_states.append(tag)\n",
    "\n",
    "    return [[tag_states],[]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Solver:\n",
    "    def __init__(self): \n",
    "        self.M =None\n",
    "        self.pi=None #initial\n",
    "        self.A =None #Transition\n",
    "        self.B =None #emission\n",
    "        self.word2idx =None\n",
    "        self.tag2idx= None  \n",
    "        \n",
    "\n",
    "            \n",
    "    def train(self,data):\n",
    "        word2idx,tag2idx = {},{}  #Word Vocabulary with word as key and word_idx as value ,#Tag Vocabulary with Tag as key and Tag_idx as value\n",
    "        word_idx,tag_idx = 0,0  #counter for words , tags\n",
    "        Xtrain,Ytrain = [],[]    #for storing overall Sentence & Tag sequences\n",
    "        currentX,currentY = [],[]  #to store current word sequences (observed Data) & tag sequences (unobserved Data)\n",
    "        for sentence in data:\n",
    "            for word,tag in zip(sentence[0],sentence[1]): \n",
    "                if word not in word2idx:\n",
    "                        word2idx[word] = word_idx\n",
    "                        word_idx += 1\n",
    "                currentX.append(word2idx[word])\n",
    "\n",
    "                if tag not in tag2idx: \n",
    "                    tag2idx[tag] = tag_idx\n",
    "                    tag_idx += 1\n",
    "                currentY.append(tag2idx[tag])\n",
    "            Xtrain.append(currentX)\n",
    "            Ytrain.append(currentY)\n",
    "            currentX = []\n",
    "            currentY = []\n",
    "\n",
    "        V = len(word2idx) + 1  #Vocabulary Size\n",
    "\n",
    "        # find hidden state, transition matrix and pi\n",
    "        M = max(max(y) for y in Ytrain) + 1 #find total number of hiddent states\n",
    "        A = np.ones((M, M))*(10e-2) # add-one smoothing\n",
    "        pi = np.zeros(M) #initial Matrix\n",
    "\n",
    "        for y in Ytrain:\n",
    "            pi[y[0]] += 1\n",
    "            for i in xrange(len(y)-1):\n",
    "                A[y[i], y[i+1]] += 1\n",
    "\n",
    "        # turn it into a probability matrix\n",
    "        A /= A.sum(axis=1, keepdims=True) #state transition matrix\n",
    "        pi /= pi.sum() #emission matrix\n",
    "\n",
    "        # find the observation matrix\n",
    "        B = np.ones((M, V))*(10e-2) # add smoothing\n",
    "        for x, y in zip(Xtrain, Ytrain):\n",
    "            for xi, yi in zip(x, y):\n",
    "                B[yi, xi] += 1\n",
    "        B /= B.sum(axis=1, keepdims=True)\n",
    "\n",
    "        self.M=M\n",
    "        self.pi = pi\n",
    "        self.A = A\n",
    "        self.B = B \n",
    "        self.word2idx = word2idx\n",
    "        self.tag2idx= tag2idx  \n",
    "\n",
    "    def HMM(self, x):\n",
    "        # returns the most likely state sequence given observed sequence x\n",
    "        # using the Viterbi algorithm \n",
    "        \n",
    "        x = [self.word2idx[word] for word in x] \n",
    "\n",
    "        T = len(x)\n",
    "        delta = np.zeros((T, self.M))\n",
    "        psi = np.zeros((T, self.M))\n",
    "        delta[0] = np.log(self.pi) + np.log(self.B[:,x[0]]) \n",
    "        for t in xrange(1, T):\n",
    "            for j in xrange(self.M):\n",
    "                delta[t,j] = np.max(delta[t-1] + np.log(self.A[:,j])) + np.log(self.B[j, x[t]])\n",
    "                psi[t,j] = np.argmax(delta[t-1] + np.log(self.A[:,j]))\n",
    "\n",
    "        # backtrack\n",
    "        states = np.zeros(T, dtype=np.int32)\n",
    "        states[T-1] = np.argmax(delta[T-1]) #Last word most probable state\n",
    "        for t in xrange(T-2, -1, -1):\n",
    "            states[t] = psi[t+1, states[t+1]]\n",
    "        \n",
    "        tag_states=[]\n",
    "        for i in range(len(states)):\n",
    "            for tag,tag_idx in self.tag2idx.iteritems():\n",
    "                if tag_idx==states[i]: tag_states.append(tag)\n",
    "            \n",
    "        return [[tag_states],[]]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solve = Solver()\n",
    "solve.train(trainData)\n",
    "states=solve.HMM(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['adp',\n",
       "   'det',\n",
       "   'adj',\n",
       "   'noun',\n",
       "   '.',\n",
       "   'noun',\n",
       "   'verb',\n",
       "   'det',\n",
       "   'noun',\n",
       "   'conj',\n",
       "   'verb',\n",
       "   'pron',\n",
       "   'adp',\n",
       "   'det',\n",
       "   'adj',\n",
       "   'noun',\n",
       "   '.']],\n",
       " []]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 45298)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve.B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=np.array(([2,8,3],[4,5,6]),dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.argmax(x[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=[1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(\"{0:.2f}\".format(0.000000008))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
