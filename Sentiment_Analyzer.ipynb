{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building our own sentiment Analyzer  \n",
    "Data  \n",
    "https://www.cs.jhu.edu/~mdredze/datasets/sentiment/index2.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read  \n",
    " - Interpretation of Logistic Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "import numpy as np \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing beautifulSoup for XML parsing\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing word_lemmatizer \n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generating all the stopwords(Already have a set of stopwords)\n",
    "stopwords = set(w.rstrip() for w in open('./data/stopwords.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reading positive reviews  \n",
    "positive_reviews = BeautifulSoup(open('./data/sentiment_analyzer/electronics/positive.review').read(),\"lxml\")\n",
    "positive_reviews = positive_reviews.findAll('review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<review_text>\n",
       " I purchased this unit due to frequent blackouts in my area and 2 power supplies going bad.  It will run my cable modem, router, PC, and LCD monitor for 5 minutes.  This is more than enough time to save work and shut down.   Equally important, I know that my electronics are receiving clean power.\n",
       " \n",
       " I feel that this investment is minor compared to the loss of valuable data or the failure of equipment due to a power spike or an irregular power supply.\n",
       " \n",
       " As always, Amazon had it to me in &lt;2 business days\n",
       " </review_text>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sample of positive reviews\n",
    "positive_reviews[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reading Negative Reviews \n",
    "negative_reviews = BeautifulSoup(open('./data/sentiment_analyzer/electronics/negative.review').read(),\"lxml\")\n",
    "negative_reviews = negative_reviews.findAll('review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<review_text>\n",
       " cons\n",
       " tips extremely easy on carpet and if you have a lot of cds stacked at the top\n",
       " \n",
       " poorly designed, it is a vertical cd rack that doesnt have individual slots for cds, so if you want a cd from the bottom of a stack you have basically pull the whole stack to get to it\n",
       " \n",
       " putting it together was a pain, the one i bought i had to break a piece of metal just to fit it in its guide holes.\n",
       " \n",
       " again..poorly designed... doesnt even fit cds that well, there are gaps, and the cd casses are loose fitting\n",
       " \n",
       " pros\n",
       " ..........\n",
       " i guess it can hold a lot of cds....\n",
       " </review_text>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sample of negative reviews \n",
    "negative_reviews[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n",
      "<class 'bs4.element.ResultSet'>\n"
     ]
    }
   ],
   "source": [
    "#Class of positive & Negative review\n",
    "print(type(positive_reviews))\n",
    "print(type(negative_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffling Positive Review and Balancing with negative review  (so that the classifier is not biased)\n",
    "np.random.shuffle(positive_reviews) \n",
    "positive_reviews = positive_reviews[:len(negative_reviews)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating Dictionary(Most important Code)\n",
    "\n",
    "def my_tokenizer(s): \n",
    "    s =s.lower()   #Lowercasing all the words\n",
    "    tokens = nltk.tokenize.word_tokenize(s)  #Tokenize the test\n",
    "    tokens = [t for t in tokens if len(t)>2] #only word len greater than 2 is useful \n",
    "    tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens] \n",
    "    tokens = [t for t in tokens if t not in stopwords]\n",
    "    return tokens\n",
    "\n",
    "positive_tokenized = [] \n",
    "negative_tokenized = []\n",
    "\n",
    "word_index_map = {} \n",
    "current_index = 0  \n",
    "\n",
    "'''Reading all the reviews(positive+negative) and tokenizing them and adding \n",
    "to dictionary''' \n",
    "for review in positive_reviews: \n",
    "    tokens = my_tokenizer(review.text) \n",
    "    positive_tokenized.append(tokens)\n",
    "    for token in tokens: \n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index +=1\n",
    "\n",
    "for review in negative_reviews: \n",
    "    tokens = my_tokenizer(review.text)  \n",
    "    negative_tokenized.append(tokens)\n",
    "    for token in tokens: \n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index +=1  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Vecotrizing all the reviews as per Hashmap created Above'''            \n",
    "def tokens_to_vector(tokens,label):\n",
    "    x = np.zeros(len(word_index_map)+1) \n",
    "    for t in tokens:\n",
    "        i = word_index_map[t]\n",
    "        x[i] +=1  \n",
    "    x=x/x.sum() #Dividing by total no of words to get frequency\n",
    "    x[-1] = label \n",
    "    return x\n",
    "    \n",
    "N = len(positive_tokenized) + len(negative_tokenized) \n",
    "data = np.zeros((N,len(word_index_map)+1))\n",
    "i=0 \n",
    "\n",
    "for tokens in positive_tokenized:\n",
    "    xy = tokens_to_vector(tokens,1)   \n",
    "    data[i,:] = xy\n",
    "    i +=1 \n",
    "    \n",
    "for tokens in negative_tokenized:\n",
    "    xy = tokens_to_vector(tokens,0)   \n",
    "    data[i,:] = xy\n",
    "    i +=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 11092)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11082</th>\n",
       "      <th>11083</th>\n",
       "      <th>11084</th>\n",
       "      <th>11085</th>\n",
       "      <th>11086</th>\n",
       "      <th>11087</th>\n",
       "      <th>11088</th>\n",
       "      <th>11089</th>\n",
       "      <th>11090</th>\n",
       "      <th>11091</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 11092 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5         6      \\\n",
       "0  0.052632  0.052632  0.052632  0.052632  0.052632  0.052632  0.052632   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.041667  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      7         8         9      ...    11082  11083  11084  11085  11086  \\\n",
       "0  0.052632  0.052632  0.052632  ...      0.0    0.0    0.0    0.0    0.0   \n",
       "1  0.000000  0.000000  0.000000  ...      0.0    0.0    0.0    0.0    0.0   \n",
       "2  0.000000  0.000000  0.000000  ...      0.0    0.0    0.0    0.0    0.0   \n",
       "3  0.000000  0.000000  0.000000  ...      0.0    0.0    0.0    0.0    0.0   \n",
       "4  0.000000  0.000000  0.000000  ...      0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   11087  11088  11089  11090  11091  \n",
       "0    0.0    0.0    0.0    0.0    1.0  \n",
       "1    0.0    0.0    0.0    0.0    1.0  \n",
       "2    0.0    0.0    0.0    0.0    1.0  \n",
       "3    0.0    0.0    0.0    0.0    1.0  \n",
       "4    0.0    0.0    0.0    0.0    1.0  \n",
       "\n",
       "[5 rows x 11092 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffling the Dataset\n",
    "np.random.shuffle(data)\n",
    "\n",
    "X = data[:,:-1]\n",
    "Y = data[:,-1] \n",
    "\n",
    "Xtrain = X[:-100,]  \n",
    "Ytrain = Y[:-100,] \n",
    "Xtest = X[-100:,]\n",
    "Ytest = Y[-100:,]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Rate 0.78\n"
     ]
    }
   ],
   "source": [
    "#Fitting Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(Xtrain,Ytrain)\n",
    "print(\"Classification Rate\",model.score(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try -0.632834489656\n",
      "quality 1.48316681818\n",
      "bit 0.631458153886\n",
      "love 1.20224822236\n",
      "ha 0.692653358215\n",
      "you 0.927154411809\n",
      "returned -0.798111049778\n",
      "comfortable 0.67699433972\n",
      "returning -0.538321093051\n",
      "paper 0.610456451134\n",
      "stopped -0.531356631512\n",
      "waste -0.997220626004\n",
      "cable 0.57562817939\n",
      "easy 1.71028892862\n",
      "space 0.514029674704\n",
      "this -0.505372769283\n",
      "value 0.510722942708\n",
      "n't -1.91667978498\n",
      "laptop 0.519164633743\n",
      "pretty 0.758727773898\n",
      "fast 0.942121103523\n",
      "wa -1.73732892904\n",
      "return -1.18556940429\n",
      "excellent 1.40768104498\n",
      "junk -0.534164294678\n",
      "tried -0.724317348768\n",
      "money -1.09459245024\n",
      "week -0.702914264907\n",
      "highly 0.888158812949\n",
      "unit -0.589855093288\n",
      "expected 0.557581753837\n",
      "called -0.505371445335\n",
      "card -0.522243217123\n",
      "happy 0.58221948179\n",
      "little 0.994786240633\n",
      "bad -0.766422975291\n",
      "speaker 0.883976815401\n",
      "item -0.949091620661\n",
      "poor -0.784861264155\n",
      "customer -0.637930421638\n",
      "perfect 1.01623949028\n",
      "warranty -0.612449647495\n",
      "recommend 0.532743856313\n",
      "then -1.1604944055\n",
      "refund -0.575304636178\n",
      "price 2.85886502676\n",
      "using 0.689825387421\n",
      "support -0.884797327567\n",
      "sound 1.13786689847\n",
      "doe -1.11435400894\n",
      "memory 0.856839873483\n",
      "month -0.576307358816\n",
      "hour -0.561858280321\n",
      "lot 0.668549652942\n",
      "company -0.56907685777\n",
      "time -0.623476345428\n",
      "fit 0.56698249112\n",
      "buy -0.849943168853\n",
      "'ve 0.792295307843\n"
     ]
    }
   ],
   "source": [
    "#Interpreting each word coefficient in logistic regression\n",
    "threshold = 0.5 \n",
    "for word,index in word_index_map.items():\n",
    "    weight = model.coef_[0][index]\n",
    "    if weight > threshold or weight <-threshold: \n",
    "        print(word,weight) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
