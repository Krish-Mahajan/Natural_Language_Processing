{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd -Order Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p(w(t)|w(t-1),w(t-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a model , \n",
    "Generate new Phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data  \n",
    "- Collection of Robert Frost Poems  \n",
    "- Text is just a bunch of poems concatenated  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import string "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Initially we need to find following  \n",
    " - Initial Distribution of first word \n",
    " - Second word distribution(won't have 2 previous words) \n",
    " - End of line distribution(w(t-2),w(t-1) $\\rightarrow$ END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial = {} #pdf for start of the phrase\n",
    "second_word = {} #pdf for second_word of the phrase\n",
    "transitions = {}  # Dictionary for second order transitions \n",
    "\n",
    "'''Removes punctuation from a dict''' \n",
    "translator = str.maketrans({key: None for key in string.punctuation})\n",
    "def remove_punctuation(s):\n",
    "    return s.translate(translator)  \n",
    "\n",
    "def add2dict(d,k,v):\n",
    "    if k not in d: d[k]=[]\n",
    "    d[k].append(v)\n",
    "\n",
    "\n",
    "for line in open(\"./data/second_order_markov/robert_frost.txt\"):\n",
    "    '''Tokenizing each sentence and removing punctuation'''\n",
    "    tokens =remove_punctuation(line.rstrip().lower()).split() \n",
    "    T = len(tokens)\n",
    "    for i in range(T):\n",
    "        t=tokens[i]\n",
    "        if i==0 : initial[t] = initial.get(t,0.)+1  #First Word\n",
    "        else: \n",
    "            t_1= tokens[i-1]\n",
    "            if i==T-1:\n",
    "                add2dict(transitions,(t_1,t),'END') #Need to add for tranisition \n",
    "            if i==1:\n",
    "                add2dict(second_word,t_1,t)  #Now add to second_word\n",
    "            else:\n",
    "                t_2 = tokens[i-2]\n",
    "                add2dict(transitions,(t_2,t_1),t)  #Again transitiom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tree',\n",
       " 'voice',\n",
       " 'swamp',\n",
       " 'tree',\n",
       " 'barkless',\n",
       " 'hole',\n",
       " 'leak',\n",
       " 'cliff',\n",
       " 'likeness',\n",
       " 'whole',\n",
       " 'small',\n",
       " 'moment',\n",
       " 'bird',\n",
       " 'single',\n",
       " 'brush',\n",
       " 'piercing',\n",
       " 'governor',\n",
       " 'rockstrewn',\n",
       " 'bead',\n",
       " 'little',\n",
       " 'shelfs',\n",
       " 'chimney',\n",
       " 'few',\n",
       " 'brook',\n",
       " 'broken',\n",
       " 'note',\n",
       " 'friend',\n",
       " 'bill',\n",
       " 'winter',\n",
       " 'featherhammer']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_word[\"a\"] #if my first word is \"a\" then second word can be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fall', 'just', 'hold']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitions[('we', 'can')] #if my first two word is we can then possible third word can be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#normalize the initial distributions \n",
    "initial_total = sum(initial.values()) \n",
    "for t,c in initial.items():\n",
    "    initial[t] = c/initial_total  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Normalising Transition and second dictionary \n",
    "def list2pdict(ts):\n",
    "    d= {} \n",
    "    n = len(ts) \n",
    "    for t in ts:\n",
    "        d[t] = d.get(t,0.) +1 \n",
    "    for t,c in d.items():\n",
    "        d[t] = c/n \n",
    "    return d \n",
    "    \n",
    "for t_1,ts in second_word.items():\n",
    "    second_word[t_1] = list2pdict(ts) \n",
    "\n",
    "for k,ts in transitions.items():\n",
    "    transitions[k] = list2pdict(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'END': 0.4, 'and': 0.2, 'both': 0.2, 'i': 0.2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitions[('each', 'other')] #Now each dictionary is changed in to a probability dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"Function to return a sample word from dictionary\"\n",
    "def sample_word(d):\n",
    "    p0 = np.random.random()\n",
    "    cumulative =0 \n",
    "    for t,p in d.items():\n",
    "        cumulative +=p \n",
    "        if p0 < cumulative: \n",
    "            return t \n",
    "    assert(False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last night was one of them put together\n",
      "till well toward noon when the heat\n",
      "except it seemed the poetesss life\n",
      "to shut you up ill tell you what you show me you remember\n"
     ]
    }
   ],
   "source": [
    "\"Function to generate Random Sentences\"\n",
    "def generate():\n",
    "    for i in range(4): \n",
    "        sentence=[] \n",
    "        w0 = sample_word(initial)\n",
    "        sentence.append(w0)  \n",
    "\n",
    "        w1 = sample_word(second_word[w0])\n",
    "        sentence.append(w1) \n",
    "\n",
    "        while True: \n",
    "            w2 = sample_word(transitions[(w0,w1)])\n",
    "            if w2 =='END':\n",
    "                break\n",
    "            sentence.append(w2)\n",
    "            w0=w1\n",
    "            w1=w2 \n",
    "        print(' '.join(sentence)) \n",
    "\n",
    "generate()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two roads diverged ! in a yellow wood ,\n",
      "two roads diverged  in a yellow wood \n",
      "['two', 'roads', 'diverged', 'in', 'a', 'yellow', 'wood']\n"
     ]
    }
   ],
   "source": [
    "line = \"Two roads diverged ! in a yellow wood ,\"\n",
    "print(line.rstrip().lower()) \n",
    "print(remove_punctuation(line.rstrip().lower()))\n",
    "print(remove_punctuation(line.rstrip().lower()).split()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
